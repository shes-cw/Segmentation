{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from glob import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, MaxPool2D, Conv2DTranspose, Concatenate, Input\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau, CSVLogger"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seeding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"midterm\"] = str(42)\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "height = 256\n",
    "width = 256\n",
    "\n",
    "batch_size = 16\n",
    "lr = 2e-4\n",
    "epochs = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"dataset\"\n",
    "\n",
    "files_dir = \"files\"\n",
    "model_file = os.path.join(files_dir, \"unet.h5\")\n",
    "log_file = os.path.join(files_dir, \"log.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dir(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dir(files_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building UNET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CBAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_attention_module(x, ratio=8):\n",
    "    channel = x.shape[-1]\n",
    "    \n",
    "    l1 = Dense(channel//ratio, activation=\"relu\", use_bias=False)\n",
    "    l2 = Dense(channel, use_bias=False)\n",
    "    \n",
    "    x1 = GlobalAveragePooling2D()(x)\n",
    "    x1 = l1(x1)\n",
    "    x1 = l2(x1)\n",
    "    \n",
    "    x2 = GlobalMaxPooling2D()(x)\n",
    "    x2 = l1(x2)\n",
    "    x2 = l2(x2)\n",
    "    \n",
    "    feats = x1 + x2\n",
    "    feats = Activation(\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_attention_module(x):\n",
    "    x1 = tf.reduce_mean(x, axis=-1)\n",
    "    x1 = tf.expand_dims(x1, axis=-1)\n",
    "    \n",
    "    x2 = tf.reduce_max(x, axis=-1)\n",
    "    x2 = tf.expand_dims(x2, axis=-1)\n",
    "    \n",
    "    feats = Concatenate()([x1, x2])\n",
    "    feats = Conv2D(1, kernel_size=7, padding=\"same\", activation=\"sigmoid\")(feats)\n",
    "    \n",
    "    feats = Multiply()([x, feats])\n",
    "    return feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cbam(x):\n",
    "    x = channel_attention_module(x)\n",
    "    x = spatial_attention_module(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conv Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(inputs, num_filters):\n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = Conv2D(num_filters, 3, padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    \n",
    "    x = cbam(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decoder Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder_block(inputs, skip, num_filters):\n",
    "    x = Conv2DTranspose(num_filters, (2, 2), strides=2, padding=\"same\")(inputs)\n",
    "    x = Concatenate()([x, skip])\n",
    "    x = conv_block(x, num_filters)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_unet(input_shape):\n",
    "    \"\"\" Inputs \"\"\"\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    \"\"\" ResNet50 Encoder \"\"\"\n",
    "    resnet50 = ResNet50(include_top=False, weights=\"imagenet\", input_tensor=inputs)\n",
    "    \n",
    "    s1 = resnet50.get_layer(\"input_1\").output\n",
    "    s2 = resnet50.get_layer(\"conv1_relu\").output\n",
    "    s3 = resnet50.get_layer(\"conv2_block3_out\").output\n",
    "    s4 = resnet50.get_layer(\"conv3_block4_out\").output\n",
    "    \n",
    "    \"\"\" Bridge \"\"\"\n",
    "    b1 = resnet50.get_layer(\"conv4_block6_out\").output\n",
    "    \n",
    "    \"\"\" Decoder \"\"\"\n",
    "    d1 = decoder_block(b1, s4, 512)\n",
    "    d2 = decoder_block(d1, s3, 256)\n",
    "    d3 = decoder_block(d2, s2, 128)\n",
    "    d4 = decoder_block(d3, s1, 64)\n",
    "    \n",
    "    outputs = Conv2D(1, 1, padding=\"same\", activation=\"sigmoid\")(d4)\n",
    "    \n",
    "    model = Model(inputs, outputs, name=\"UNET\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    train_x = sorted(glob(os.path.join(path, \"train\", \"images\", \"*\")))\n",
    "    train_y = sorted(glob(os.path.join(path, \"train\", \"masks\", \"*\")))\n",
    "    \n",
    "    valid_x = sorted(glob(os.path.join(path, \"valid\", \"images\", \"*\")))\n",
    "    valid_y = sorted(glob(os.path.join(path, \"valid\", \"masks\", \"*\")))\n",
    "    \n",
    "    return (train_x, train_y), (valid_x, valid_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mask(path):\n",
    "    path = path.decode()\n",
    "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    x = cv2.resize(x, (width, height))\n",
    "    x = x/255.0\n",
    "    x = np.expand_dims(x, axis=-1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tf.data pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_parse(x, y):\n",
    "    def _parse(x, y):\n",
    "        x = read_image(x)\n",
    "        y = read_mask(y)\n",
    "        return x, y\n",
    "    \n",
    "    x, y = tf.numpy_function(_parse, [x, y], [tf.float64, tf.float64])\n",
    "    x.set_shape([height, width, 3])\n",
    "    y.set_shape([height, width, 1])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_dataset(x, y, batch=8):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
    "    dataset = dataset.map(tf_parse, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(batch)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 536 - 536\n",
      "Valid: 67 - 67\n"
     ]
    }
   ],
   "source": [
    "(train_x, train_y), (valid_x, valid_y) = load_data(dataset_path)\n",
    "print(f\"Train: {len(train_x)} - {len(train_y)}\")\n",
    "print(f\"Valid: {len(valid_x)} - {len(valid_y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
    "valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (height, width, 3)\n",
    "model = build_unet(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"UNET\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv1_pad (ZeroPadding2D)      (None, 262, 262, 3)  0           ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv1_conv (Conv2D)            (None, 128, 128, 64  9472        ['conv1_pad[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_bn (BatchNormalization)  (None, 128, 128, 64  256         ['conv1_conv[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv1_relu (Activation)        (None, 128, 128, 64  0           ['conv1_bn[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pad (ZeroPadding2D)      (None, 130, 130, 64  0           ['conv1_relu[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " pool1_pool (MaxPooling2D)      (None, 64, 64, 64)   0           ['pool1_pad[0][0]']              \n",
      "                                                                                                  \n",
      " conv2_block1_1_conv (Conv2D)   (None, 64, 64, 64)   4160        ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block1_0_conv (Conv2D)   (None, 64, 64, 256)  16640       ['pool1_pool[0][0]']             \n",
      "                                                                                                  \n",
      " conv2_block1_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block1_0_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block1_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
      "                                                                  'conv2_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block1_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block2_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block2_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block2_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block2_add (Add)         (None, 64, 64, 256)  0           ['conv2_block1_out[0][0]',       \n",
      "                                                                  'conv2_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block2_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_conv (Conv2D)   (None, 64, 64, 64)   16448       ['conv2_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2_block3_1_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_1_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_2_conv (Conv2D)   (None, 64, 64, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_2_bn (BatchNormal  (None, 64, 64, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_2_relu (Activatio  (None, 64, 64, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv2_block3_3_conv (Conv2D)   (None, 64, 64, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv2_block3_3_bn (BatchNormal  (None, 64, 64, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv2_block3_add (Add)         (None, 64, 64, 256)  0           ['conv2_block2_out[0][0]',       \n",
      "                                                                  'conv2_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv2_block3_out (Activation)  (None, 64, 64, 256)  0           ['conv2_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_conv (Conv2D)   (None, 32, 32, 128)  32896       ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block1_0_conv (Conv2D)   (None, 32, 32, 512)  131584      ['conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block1_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block1_0_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block1_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
      "                                                                  'conv3_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block1_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block1_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block2_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block2_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block2_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block2_add (Add)         (None, 32, 32, 512)  0           ['conv3_block1_out[0][0]',       \n",
      "                                                                  'conv3_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block2_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block2_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block3_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block3_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block3_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block3_add (Add)         (None, 32, 32, 512)  0           ['conv3_block2_out[0][0]',       \n",
      "                                                                  'conv3_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block3_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block3_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_conv (Conv2D)   (None, 32, 32, 128)  65664       ['conv3_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv3_block4_1_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_1_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_2_conv (Conv2D)   (None, 32, 32, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_2_bn (BatchNormal  (None, 32, 32, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_2_relu (Activatio  (None, 32, 32, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv3_block4_3_conv (Conv2D)   (None, 32, 32, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv3_block4_3_bn (BatchNormal  (None, 32, 32, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv3_block4_add (Add)         (None, 32, 32, 512)  0           ['conv3_block3_out[0][0]',       \n",
      "                                                                  'conv3_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv3_block4_out (Activation)  (None, 32, 32, 512)  0           ['conv3_block4_add[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_conv (Conv2D)   (None, 16, 16, 256)  131328      ['conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block1_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block1_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block1_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block1_0_conv (Conv2D)   (None, 16, 16, 1024  525312      ['conv3_block4_out[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_0_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block1_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
      "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block1_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block1_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block1_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block2_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block2_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block2_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block2_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block2_add (Add)         (None, 16, 16, 1024  0           ['conv4_block1_out[0][0]',       \n",
      "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block2_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block2_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block2_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block3_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block3_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block3_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block3_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block3_add (Add)         (None, 16, 16, 1024  0           ['conv4_block2_out[0][0]',       \n",
      "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block3_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block3_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block4_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block4_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block4_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block4_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block4_add (Add)         (None, 16, 16, 1024  0           ['conv4_block3_out[0][0]',       \n",
      "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block4_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block4_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block5_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block5_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block5_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block5_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block5_add (Add)         (None, 16, 16, 1024  0           ['conv4_block4_out[0][0]',       \n",
      "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block5_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block5_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_1_conv (Conv2D)   (None, 16, 16, 256)  262400      ['conv4_block5_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv4_block6_1_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_1_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_2_conv (Conv2D)   (None, 16, 16, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
      "                                                                                                  \n",
      " conv4_block6_2_bn (BatchNormal  (None, 16, 16, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " conv4_block6_2_relu (Activatio  (None, 16, 16, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " conv4_block6_3_conv (Conv2D)   (None, 16, 16, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_3_bn (BatchNormal  (None, 16, 16, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " conv4_block6_add (Add)         (None, 16, 16, 1024  0           ['conv4_block5_out[0][0]',       \n",
      "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
      "                                                                                                  \n",
      " conv4_block6_out (Activation)  (None, 16, 16, 1024  0           ['conv4_block6_add[0][0]']       \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 32, 32, 512)  2097664    ['conv4_block6_out[0][0]']       \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 32, 32, 1024  0           ['conv2d_transpose[0][0]',       \n",
      "                                )                                 'conv3_block4_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 32, 32, 512)  4719104     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 32, 32, 512)  2048       ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 32, 32, 512)  0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 512)  2359808     ['activation[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 512)  2048       ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 32, 32, 512)  0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 512)         0           ['activation_1[0][0]']           \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling2d (GlobalMa  (None, 512)         0           ['activation_1[0][0]']           \n",
      " xPooling2D)                                                                                      \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 64)           32768       ['global_average_pooling2d[0][0]'\n",
      "                                                                 , 'global_max_pooling2d[0][0]']  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 512)          32768       ['dense[0][0]',                  \n",
      "                                                                  'dense[1][0]']                  \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOpLamb  (None, 512)         0           ['dense_1[0][0]',                \n",
      " da)                                                              'dense_1[1][0]']                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 512)          0           ['tf.__operators__.add[0][0]']   \n",
      "                                                                                                  \n",
      " multiply (Multiply)            (None, 32, 32, 512)  0           ['activation_1[0][0]',           \n",
      "                                                                  'activation_2[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean (TFOpLambd  (None, 32, 32)      0           ['multiply[0][0]']               \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.math.reduce_max (TFOpLambda  (None, 32, 32)      0           ['multiply[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " tf.expand_dims (TFOpLambda)    (None, 32, 32, 1)    0           ['tf.math.reduce_mean[0][0]']    \n",
      "                                                                                                  \n",
      " tf.expand_dims_1 (TFOpLambda)  (None, 32, 32, 1)    0           ['tf.math.reduce_max[0][0]']     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 32, 32, 2)    0           ['tf.expand_dims[0][0]',         \n",
      "                                                                  'tf.expand_dims_1[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 32, 32, 1)    99          ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_1 (Multiply)          (None, 32, 32, 512)  0           ['multiply[0][0]',               \n",
      "                                                                  'conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 64, 64, 256)  524544     ['multiply_1[0][0]']             \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 64, 64, 512)  0           ['conv2d_transpose_1[0][0]',     \n",
      "                                                                  'conv2_block3_out[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 64, 64, 256)  1179904     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  590080      ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 64, 64, 256)  1024       ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 64, 64, 256)  0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " global_average_pooling2d_1 (Gl  (None, 256)         0           ['activation_4[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_1 (Global  (None, 256)         0           ['activation_4[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 32)           8192        ['global_average_pooling2d_1[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_1[0][0]'] \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 256)          8192        ['dense_2[0][0]',                \n",
      "                                                                  'dense_2[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TFOpLa  (None, 256)         0           ['dense_3[0][0]',                \n",
      " mbda)                                                            'dense_3[1][0]']                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 256)          0           ['tf.__operators__.add_1[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_2 (Multiply)          (None, 64, 64, 256)  0           ['activation_4[0][0]',           \n",
      "                                                                  'activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_1 (TFOpLam  (None, 64, 64)      0           ['multiply_2[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_1 (TFOpLamb  (None, 64, 64)      0           ['multiply_2[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_2 (TFOpLambda)  (None, 64, 64, 1)    0           ['tf.math.reduce_mean_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_3 (TFOpLambda)  (None, 64, 64, 1)    0           ['tf.math.reduce_max_1[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 64, 64, 2)    0           ['tf.expand_dims_2[0][0]',       \n",
      "                                                                  'tf.expand_dims_3[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 1)    99          ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_3 (Multiply)          (None, 64, 64, 256)  0           ['multiply_2[0][0]',             \n",
      "                                                                  'conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 128, 128, 12  131200     ['multiply_3[0][0]']             \n",
      " spose)                         8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 128, 128, 19  0           ['conv2d_transpose_2[0][0]',     \n",
      "                                2)                                'conv1_relu[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 12  221312      ['concatenate_4[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 128, 128, 12  512        ['conv2d_6[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_4[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['activation_6[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 128, 128, 12  512        ['conv2d_7[0][0]']               \n",
      " rmalization)                   8)                                                                \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 128, 128, 12  0           ['batch_normalization_5[0][0]']  \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " global_average_pooling2d_2 (Gl  (None, 128)         0           ['activation_7[0][0]']           \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_2 (Global  (None, 128)         0           ['activation_7[0][0]']           \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 16)           2048        ['global_average_pooling2d_2[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 128)          2048        ['dense_4[0][0]',                \n",
      "                                                                  'dense_4[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TFOpLa  (None, 128)         0           ['dense_5[0][0]',                \n",
      " mbda)                                                            'dense_5[1][0]']                \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 128)          0           ['tf.__operators__.add_2[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_4 (Multiply)          (None, 128, 128, 12  0           ['activation_7[0][0]',           \n",
      "                                8)                                'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_2 (TFOpLam  (None, 128, 128)    0           ['multiply_4[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_2 (TFOpLamb  (None, 128, 128)    0           ['multiply_4[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_4 (TFOpLambda)  (None, 128, 128, 1)  0           ['tf.math.reduce_mean_2[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_5 (TFOpLambda)  (None, 128, 128, 1)  0           ['tf.math.reduce_max_2[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 128, 128, 2)  0           ['tf.expand_dims_4[0][0]',       \n",
      "                                                                  'tf.expand_dims_5[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 128, 128, 1)  99          ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_5 (Multiply)          (None, 128, 128, 12  0           ['multiply_4[0][0]',             \n",
      "                                8)                                'conv2d_8[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 256, 256, 64  32832      ['multiply_5[0][0]']             \n",
      " spose)                         )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 256, 256, 67  0           ['conv2d_transpose_3[0][0]',     \n",
      "                                )                                 'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 64  38656       ['concatenate_6[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 256, 256, 64  256        ['conv2d_9[0][0]']               \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 256, 256, 64  0           ['batch_normalization_6[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 256, 256, 64  36928       ['activation_9[0][0]']           \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 256, 256, 64  256        ['conv2d_10[0][0]']              \n",
      " rmalization)                   )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 256, 256, 64  0           ['batch_normalization_7[0][0]']  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " global_average_pooling2d_3 (Gl  (None, 64)          0           ['activation_10[0][0]']          \n",
      " obalAveragePooling2D)                                                                            \n",
      "                                                                                                  \n",
      " global_max_pooling2d_3 (Global  (None, 64)          0           ['activation_10[0][0]']          \n",
      " MaxPooling2D)                                                                                    \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 8)            512         ['global_average_pooling2d_3[0][0\n",
      "                                                                 ]',                              \n",
      "                                                                  'global_max_pooling2d_3[0][0]'] \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 64)           512         ['dense_6[0][0]',                \n",
      "                                                                  'dense_6[1][0]']                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TFOpLa  (None, 64)          0           ['dense_7[0][0]',                \n",
      " mbda)                                                            'dense_7[1][0]']                \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 64)           0           ['tf.__operators__.add_3[0][0]'] \n",
      "                                                                                                  \n",
      " multiply_6 (Multiply)          (None, 256, 256, 64  0           ['activation_10[0][0]',          \n",
      "                                )                                 'activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " tf.math.reduce_mean_3 (TFOpLam  (None, 256, 256)    0           ['multiply_6[0][0]']             \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.math.reduce_max_3 (TFOpLamb  (None, 256, 256)    0           ['multiply_6[0][0]']             \n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.expand_dims_6 (TFOpLambda)  (None, 256, 256, 1)  0           ['tf.math.reduce_mean_3[0][0]']  \n",
      "                                                                                                  \n",
      " tf.expand_dims_7 (TFOpLambda)  (None, 256, 256, 1)  0           ['tf.math.reduce_max_3[0][0]']   \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 256, 256, 2)  0           ['tf.expand_dims_6[0][0]',       \n",
      "                                                                  'tf.expand_dims_7[0][0]']       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)             (None, 256, 256, 1)  99          ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " multiply_7 (Multiply)          (None, 256, 256, 64  0           ['multiply_6[0][0]',             \n",
      "                                )                                 'conv2d_11[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)             (None, 256, 256, 1)  65          ['multiply_7[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 20,763,981\n",
      "Trainable params: 20,729,549\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(y_true, y_pred):\n",
    "    y_true = tf.keras.layers.Flatten()(y_true)\n",
    "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    dice = (2. * intersection + 1e-15) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + 1e-15)\n",
    "    return 1.0 - dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(lr)\n",
    "model.compile(loss=dice_loss, optimizer=opt, metrics=[\"acc\"], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "        ModelCheckpoint(model_file, verbose=1, save_best_only=True),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10),\n",
    "        CSVLogger(log_file),\n",
    "        EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.6469 - acc: 0.7802 \n",
      "Epoch 1: val_loss improved from inf to 0.79571, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 544s 16s/step - loss: 0.6469 - acc: 0.7802 - val_loss: 0.7957 - val_acc: 0.1296 - lr: 2.0000e-04\n",
      "Epoch 2/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.4812 - acc: 0.8335 \n",
      "Epoch 2: val_loss did not improve from 0.79571\n",
      "34/34 [==============================] - 513s 15s/step - loss: 0.4812 - acc: 0.8335 - val_loss: 0.7970 - val_acc: 0.8106 - lr: 2.0000e-04\n",
      "Epoch 3/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.3547 - acc: 0.8554 \n",
      "Epoch 3: val_loss did not improve from 0.79571\n",
      "34/34 [==============================] - 501s 15s/step - loss: 0.3547 - acc: 0.8554 - val_loss: 0.7966 - val_acc: 0.8106 - lr: 2.0000e-04\n",
      "Epoch 4/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2720 - acc: 0.8639 \n",
      "Epoch 4: val_loss improved from 0.79571 to 0.79538, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.2720 - acc: 0.8639 - val_loss: 0.7954 - val_acc: 0.2847 - lr: 2.0000e-04\n",
      "Epoch 5/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.2237 - acc: 0.8675 \n",
      "Epoch 5: val_loss improved from 0.79538 to 0.79495, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 501s 15s/step - loss: 0.2237 - acc: 0.8675 - val_loss: 0.7950 - val_acc: 0.2385 - lr: 2.0000e-04\n",
      "Epoch 6/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1893 - acc: 0.8697 \n",
      "Epoch 6: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 506s 15s/step - loss: 0.1893 - acc: 0.8697 - val_loss: 0.8101 - val_acc: 0.2767 - lr: 2.0000e-04\n",
      "Epoch 7/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1645 - acc: 0.8703 \n",
      "Epoch 7: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.1645 - acc: 0.8703 - val_loss: 0.8294 - val_acc: 0.6875 - lr: 2.0000e-04\n",
      "Epoch 8/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1457 - acc: 0.8702 \n",
      "Epoch 8: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 511s 15s/step - loss: 0.1457 - acc: 0.8702 - val_loss: 0.8628 - val_acc: 0.8106 - lr: 2.0000e-04\n",
      "Epoch 9/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1273 - acc: 0.8714 \n",
      "Epoch 9: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.1273 - acc: 0.8714 - val_loss: 0.8806 - val_acc: 0.8032 - lr: 2.0000e-04\n",
      "Epoch 10/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1154 - acc: 0.8721 \n",
      "Epoch 10: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 515s 15s/step - loss: 0.1154 - acc: 0.8721 - val_loss: 0.8957 - val_acc: 0.8067 - lr: 2.0000e-04\n",
      "Epoch 11/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1082 - acc: 0.8723 \n",
      "Epoch 11: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 780s 23s/step - loss: 0.1082 - acc: 0.8723 - val_loss: 0.9253 - val_acc: 0.8106 - lr: 2.0000e-04\n",
      "Epoch 12/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.1006 - acc: 0.8728 \n",
      "Epoch 12: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 1712s 51s/step - loss: 0.1006 - acc: 0.8728 - val_loss: 0.9245 - val_acc: 0.8105 - lr: 2.0000e-04\n",
      "Epoch 13/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0948 - acc: 0.8733 \n",
      "Epoch 13: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 841s 25s/step - loss: 0.0948 - acc: 0.8733 - val_loss: 0.8599 - val_acc: 0.6853 - lr: 2.0000e-04\n",
      "Epoch 14/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0913 - acc: 0.8735 \n",
      "Epoch 14: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 528s 16s/step - loss: 0.0913 - acc: 0.8735 - val_loss: 0.9151 - val_acc: 0.8109 - lr: 2.0000e-04\n",
      "Epoch 15/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0891 - acc: 0.8735 \n",
      "Epoch 15: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 562s 17s/step - loss: 0.0891 - acc: 0.8735 - val_loss: 0.9258 - val_acc: 0.8110 - lr: 2.0000e-04\n",
      "Epoch 16/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0894 - acc: 0.8735 \n",
      "Epoch 16: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 510s 15s/step - loss: 0.0894 - acc: 0.8735 - val_loss: 0.9283 - val_acc: 0.8114 - lr: 2.0000e-05\n",
      "Epoch 17/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0807 - acc: 0.8747 \n",
      "Epoch 17: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 534s 16s/step - loss: 0.0807 - acc: 0.8747 - val_loss: 0.8724 - val_acc: 0.8135 - lr: 2.0000e-05\n",
      "Epoch 18/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0786 - acc: 0.8750 \n",
      "Epoch 18: val_loss did not improve from 0.79495\n",
      "34/34 [==============================] - 532s 16s/step - loss: 0.0786 - acc: 0.8750 - val_loss: 0.8025 - val_acc: 0.8171 - lr: 2.0000e-05\n",
      "Epoch 19/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0770 - acc: 0.8753 \n",
      "Epoch 19: val_loss improved from 0.79495 to 0.73031, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 516s 15s/step - loss: 0.0770 - acc: 0.8753 - val_loss: 0.7303 - val_acc: 0.8219 - lr: 2.0000e-05\n",
      "Epoch 20/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0757 - acc: 0.8755 \n",
      "Epoch 20: val_loss improved from 0.73031 to 0.66144, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 509s 15s/step - loss: 0.0757 - acc: 0.8755 - val_loss: 0.6614 - val_acc: 0.8273 - lr: 2.0000e-05\n",
      "Epoch 21/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0745 - acc: 0.8757 \n",
      "Epoch 21: val_loss improved from 0.66144 to 0.59441, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 526s 16s/step - loss: 0.0745 - acc: 0.8757 - val_loss: 0.5944 - val_acc: 0.8328 - lr: 2.0000e-05\n",
      "Epoch 22/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0733 - acc: 0.8759 \n",
      "Epoch 22: val_loss improved from 0.59441 to 0.52437, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 523s 15s/step - loss: 0.0733 - acc: 0.8759 - val_loss: 0.5244 - val_acc: 0.8389 - lr: 2.0000e-05\n",
      "Epoch 23/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0722 - acc: 0.8761 \n",
      "Epoch 23: val_loss improved from 0.52437 to 0.45556, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 512s 15s/step - loss: 0.0722 - acc: 0.8761 - val_loss: 0.4556 - val_acc: 0.8444 - lr: 2.0000e-05\n",
      "Epoch 24/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0712 - acc: 0.8762 \n",
      "Epoch 24: val_loss improved from 0.45556 to 0.39038, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 510s 15s/step - loss: 0.0712 - acc: 0.8762 - val_loss: 0.3904 - val_acc: 0.8497 - lr: 2.0000e-05\n",
      "Epoch 25/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0702 - acc: 0.8764 \n",
      "Epoch 25: val_loss improved from 0.39038 to 0.33568, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 510s 15s/step - loss: 0.0702 - acc: 0.8764 - val_loss: 0.3357 - val_acc: 0.8540 - lr: 2.0000e-05\n",
      "Epoch 26/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0693 - acc: 0.8765 \n",
      "Epoch 26: val_loss improved from 0.33568 to 0.28878, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.0693 - acc: 0.8765 - val_loss: 0.2888 - val_acc: 0.8582 - lr: 2.0000e-05\n",
      "Epoch 27/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0683 - acc: 0.8766 \n",
      "Epoch 27: val_loss improved from 0.28878 to 0.24764, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 503s 15s/step - loss: 0.0683 - acc: 0.8766 - val_loss: 0.2476 - val_acc: 0.8627 - lr: 2.0000e-05\n",
      "Epoch 28/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0674 - acc: 0.8768 \n",
      "Epoch 28: val_loss improved from 0.24764 to 0.21018, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 517s 15s/step - loss: 0.0674 - acc: 0.8768 - val_loss: 0.2102 - val_acc: 0.8676 - lr: 2.0000e-05\n",
      "Epoch 29/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0665 - acc: 0.8769 \n",
      "Epoch 29: val_loss improved from 0.21018 to 0.17527, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 523s 15s/step - loss: 0.0665 - acc: 0.8769 - val_loss: 0.1753 - val_acc: 0.8727 - lr: 2.0000e-05\n",
      "Epoch 30/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0657 - acc: 0.8770 \n",
      "Epoch 30: val_loss improved from 0.17527 to 0.14665, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 526s 16s/step - loss: 0.0657 - acc: 0.8770 - val_loss: 0.1466 - val_acc: 0.8772 - lr: 2.0000e-05\n",
      "Epoch 31/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0649 - acc: 0.8771 \n",
      "Epoch 31: val_loss improved from 0.14665 to 0.12698, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 549s 16s/step - loss: 0.0649 - acc: 0.8771 - val_loss: 0.1270 - val_acc: 0.8802 - lr: 2.0000e-05\n",
      "Epoch 32/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0642 - acc: 0.8772 \n",
      "Epoch 32: val_loss improved from 0.12698 to 0.11586, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 549s 16s/step - loss: 0.0642 - acc: 0.8772 - val_loss: 0.1159 - val_acc: 0.8819 - lr: 2.0000e-05\n",
      "Epoch 33/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0634 - acc: 0.8772 \n",
      "Epoch 33: val_loss improved from 0.11586 to 0.10870, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 531s 16s/step - loss: 0.0634 - acc: 0.8772 - val_loss: 0.1087 - val_acc: 0.8830 - lr: 2.0000e-05\n",
      "Epoch 34/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0626 - acc: 0.8773 \n",
      "Epoch 34: val_loss improved from 0.10870 to 0.10562, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 564s 17s/step - loss: 0.0626 - acc: 0.8773 - val_loss: 0.1056 - val_acc: 0.8833 - lr: 2.0000e-05\n",
      "Epoch 35/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0620 - acc: 0.8774 \n",
      "Epoch 35: val_loss improved from 0.10562 to 0.10371, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 799s 23s/step - loss: 0.0620 - acc: 0.8774 - val_loss: 0.1037 - val_acc: 0.8836 - lr: 2.0000e-05\n",
      "Epoch 36/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0612 - acc: 0.8775 \n",
      "Epoch 36: val_loss improved from 0.10371 to 0.10190, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 530s 16s/step - loss: 0.0612 - acc: 0.8775 - val_loss: 0.1019 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 37/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0607 - acc: 0.8775 \n",
      "Epoch 37: val_loss improved from 0.10190 to 0.10187, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 539s 16s/step - loss: 0.0607 - acc: 0.8775 - val_loss: 0.1019 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 38/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0602 - acc: 0.8776 \n",
      "Epoch 38: val_loss improved from 0.10187 to 0.10117, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 533s 16s/step - loss: 0.0602 - acc: 0.8776 - val_loss: 0.1012 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 39/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0596 - acc: 0.8777 \n",
      "Epoch 39: val_loss improved from 0.10117 to 0.10021, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 530s 16s/step - loss: 0.0596 - acc: 0.8777 - val_loss: 0.1002 - val_acc: 0.8840 - lr: 2.0000e-05\n",
      "Epoch 40/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0590 - acc: 0.8777 \n",
      "Epoch 40: val_loss did not improve from 0.10021\n",
      "34/34 [==============================] - 540s 16s/step - loss: 0.0590 - acc: 0.8777 - val_loss: 0.1016 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 41/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0586 - acc: 0.8777 \n",
      "Epoch 41: val_loss improved from 0.10021 to 0.09989, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 596s 17s/step - loss: 0.0586 - acc: 0.8777 - val_loss: 0.0999 - val_acc: 0.8839 - lr: 2.0000e-05\n",
      "Epoch 42/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0581 - acc: 0.8778 \n",
      "Epoch 42: val_loss did not improve from 0.09989\n",
      "34/34 [==============================] - 523s 15s/step - loss: 0.0581 - acc: 0.8778 - val_loss: 0.0999 - val_acc: 0.8839 - lr: 2.0000e-05\n",
      "Epoch 43/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0577 - acc: 0.8778 \n",
      "Epoch 43: val_loss did not improve from 0.09989\n",
      "34/34 [==============================] - 509s 15s/step - loss: 0.0577 - acc: 0.8778 - val_loss: 0.1021 - val_acc: 0.8835 - lr: 2.0000e-05\n",
      "Epoch 44/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0576 - acc: 0.8778 \n",
      "Epoch 44: val_loss improved from 0.09989 to 0.09916, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 506s 15s/step - loss: 0.0576 - acc: 0.8778 - val_loss: 0.0992 - val_acc: 0.8840 - lr: 2.0000e-05\n",
      "Epoch 45/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0570 - acc: 0.8779 \n",
      "Epoch 45: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.0570 - acc: 0.8779 - val_loss: 0.1009 - val_acc: 0.8837 - lr: 2.0000e-05\n",
      "Epoch 46/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0564 - acc: 0.8779 \n",
      "Epoch 46: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 508s 15s/step - loss: 0.0564 - acc: 0.8779 - val_loss: 0.1010 - val_acc: 0.8838 - lr: 2.0000e-05\n",
      "Epoch 47/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.8779 \n",
      "Epoch 47: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 508s 15s/step - loss: 0.0562 - acc: 0.8779 - val_loss: 0.0993 - val_acc: 0.8839 - lr: 2.0000e-05\n",
      "Epoch 48/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.8779 \n",
      "Epoch 48: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 507s 15s/step - loss: 0.0562 - acc: 0.8779 - val_loss: 0.1022 - val_acc: 0.8834 - lr: 2.0000e-05\n",
      "Epoch 49/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.8779 \n",
      "Epoch 49: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 507s 15s/step - loss: 0.0562 - acc: 0.8779 - val_loss: 0.1017 - val_acc: 0.8835 - lr: 2.0000e-05\n",
      "Epoch 50/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0565 - acc: 0.8778 \n",
      "Epoch 50: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.0565 - acc: 0.8778 - val_loss: 0.1022 - val_acc: 0.8834 - lr: 2.0000e-05\n",
      "Epoch 51/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0563 - acc: 0.8778 \n",
      "Epoch 51: val_loss did not improve from 0.09916\n",
      "34/34 [==============================] - 506s 15s/step - loss: 0.0563 - acc: 0.8778 - val_loss: 0.1015 - val_acc: 0.8833 - lr: 2.0000e-05\n",
      "Epoch 52/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0562 - acc: 0.8777 \n",
      "Epoch 52: val_loss improved from 0.09916 to 0.09692, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.0562 - acc: 0.8777 - val_loss: 0.0969 - val_acc: 0.8840 - lr: 2.0000e-05\n",
      "Epoch 53/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0555 - acc: 0.8778 \n",
      "Epoch 53: val_loss improved from 0.09692 to 0.09653, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 507s 15s/step - loss: 0.0555 - acc: 0.8778 - val_loss: 0.0965 - val_acc: 0.8841 - lr: 2.0000e-05\n",
      "Epoch 54/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0541 - acc: 0.8780 \n",
      "Epoch 54: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 507s 15s/step - loss: 0.0541 - acc: 0.8780 - val_loss: 0.0966 - val_acc: 0.8841 - lr: 2.0000e-05\n",
      "Epoch 55/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0533 - acc: 0.8782 \n",
      "Epoch 55: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 582s 17s/step - loss: 0.0533 - acc: 0.8782 - val_loss: 0.0969 - val_acc: 0.8840 - lr: 2.0000e-05\n",
      "Epoch 56/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0523 - acc: 0.8783 \n",
      "Epoch 56: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 1735s 52s/step - loss: 0.0523 - acc: 0.8783 - val_loss: 0.0998 - val_acc: 0.8835 - lr: 2.0000e-05\n",
      "Epoch 57/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0522 - acc: 0.8783 \n",
      "Epoch 57: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 521s 15s/step - loss: 0.0522 - acc: 0.8783 - val_loss: 0.1028 - val_acc: 0.8830 - lr: 2.0000e-05\n",
      "Epoch 58/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0529 - acc: 0.8781 \n",
      "Epoch 58: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 511s 15s/step - loss: 0.0529 - acc: 0.8781 - val_loss: 0.1038 - val_acc: 0.8828 - lr: 2.0000e-05\n",
      "Epoch 59/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0532 - acc: 0.8781 \n",
      "Epoch 59: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 509s 15s/step - loss: 0.0532 - acc: 0.8781 - val_loss: 0.1054 - val_acc: 0.8827 - lr: 2.0000e-05\n",
      "Epoch 60/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.8780 \n",
      "Epoch 60: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 503s 15s/step - loss: 0.0534 - acc: 0.8780 - val_loss: 0.1034 - val_acc: 0.8830 - lr: 2.0000e-05\n",
      "Epoch 61/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0539 - acc: 0.8779 \n",
      "Epoch 61: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 503s 15s/step - loss: 0.0539 - acc: 0.8779 - val_loss: 0.0991 - val_acc: 0.8836 - lr: 2.0000e-05\n",
      "Epoch 62/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0534 - acc: 0.8779 \n",
      "Epoch 62: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 503s 15s/step - loss: 0.0534 - acc: 0.8779 - val_loss: 0.0968 - val_acc: 0.8840 - lr: 2.0000e-05\n",
      "Epoch 63/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0540 - acc: 0.8778 \n",
      "Epoch 63: val_loss did not improve from 0.09653\n",
      "34/34 [==============================] - 502s 15s/step - loss: 0.0540 - acc: 0.8778 - val_loss: 0.0992 - val_acc: 0.8836 - lr: 2.0000e-05\n",
      "Epoch 64/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0589 - acc: 0.8769 \n",
      "Epoch 64: val_loss improved from 0.09653 to 0.09561, saving model to files\\unet.h5\n",
      "34/34 [==============================] - 512s 15s/step - loss: 0.0589 - acc: 0.8769 - val_loss: 0.0956 - val_acc: 0.8840 - lr: 2.0000e-06\n",
      "Epoch 65/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0516 - acc: 0.8781 \n",
      "Epoch 65: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 502s 15s/step - loss: 0.0516 - acc: 0.8781 - val_loss: 0.0967 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 66/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0501 - acc: 0.8784 \n",
      "Epoch 66: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 509s 15s/step - loss: 0.0501 - acc: 0.8784 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 67/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0496 - acc: 0.8785 \n",
      "Epoch 67: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 513s 15s/step - loss: 0.0496 - acc: 0.8785 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 68/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0492 - acc: 0.8786 \n",
      "Epoch 68: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 512s 15s/step - loss: 0.0492 - acc: 0.8786 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 69/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0489 - acc: 0.8786 \n",
      "Epoch 69: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 512s 15s/step - loss: 0.0489 - acc: 0.8786 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 70/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0486 - acc: 0.8787 \n",
      "Epoch 70: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 519s 15s/step - loss: 0.0486 - acc: 0.8787 - val_loss: 0.0969 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 71/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0484 - acc: 0.8787 \n",
      "Epoch 71: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 515s 15s/step - loss: 0.0484 - acc: 0.8787 - val_loss: 0.0969 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 72/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0482 - acc: 0.8787 \n",
      "Epoch 72: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 613s 18s/step - loss: 0.0482 - acc: 0.8787 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 73/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0480 - acc: 0.8787 \n",
      "Epoch 73: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 530s 16s/step - loss: 0.0480 - acc: 0.8787 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 74/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0479 - acc: 0.8788 \n",
      "Epoch 74: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 515s 15s/step - loss: 0.0479 - acc: 0.8788 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-06\n",
      "Epoch 75/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 75: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 502s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 76/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 76: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 502s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 77/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 77: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 506s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 78/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 78: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 512s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0970 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 79/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 79: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 510s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 80/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 80: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 502s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 81/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 81: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 505s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 82/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0477 - acc: 0.8788 \n",
      "Epoch 82: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 503s 15s/step - loss: 0.0477 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 83/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.8788 \n",
      "Epoch 83: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 506s 15s/step - loss: 0.0476 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n",
      "Epoch 84/100\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0476 - acc: 0.8788 \n",
      "Epoch 84: val_loss did not improve from 0.09561\n",
      "34/34 [==============================] - 507s 15s/step - loss: 0.0476 - acc: 0.8788 - val_loss: 0.0971 - val_acc: 0.8838 - lr: 2.0000e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14a51a880a0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=valid_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
